{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GoogleColab_synthetic_train_steps23.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qSTWY120gnaA"},"source":["# REGVAE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0MLx8nSKLkc","executionInfo":{"status":"ok","timestamp":1635263109639,"user_tz":-180,"elapsed":646,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"272b8587-fd0d-4c14-8bb6-644c0d926a1a"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 26 15:45:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","metadata":{"id":"_Ag785zwKMJv"},"source":["# ---------------------------------------------------------------------------------------------------"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPTUgYADgnaD","executionInfo":{"status":"ok","timestamp":1635263116072,"user_tz":-180,"elapsed":5916,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"6626493c-19ce-44aa-cdaa-f8d3beed1391"},"source":["import os\n","import sys\n","import numpy as np\n","import json\n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from google.colab import drive\n","import time\n","import glob\n","\n","import torch\n","from torch.nn import functional as F\n","import torch.optim as optim\n","import torchvision\n","from torchvision.utils import save_image\n","import torch.utils.data as data_utils\n","import torch.distributions as dist\n","\n","\n","from sklearn.decomposition import PCA\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.manifold import TSNE\n","import random\n","from tqdm import tqdm\n","\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 12381423808501878097, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15434776576\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 6212672082793317692\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5FkYK3jmkVX","executionInfo":{"status":"ok","timestamp":1635263116073,"user_tz":-180,"elapsed":30,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"0526b05a-0ac1-4e8f-fec1-5c6280fb4bce"},"source":["if not os.path.isdir('drive'):\n","  drive.mount('drive')\n","else:\n","  print('drive already mounted')\n","\n","base_path = os.path.join('drive', 'My Drive', 'Colab Notebooks', 'GEN')\n","if not os.path.isdir(base_path):\n","  os.makedirs(base_path)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["drive already mounted\n"]}]},{"cell_type":"code","metadata":{"id":"LCNDDe78gnaE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635263116073,"user_tz":-180,"elapsed":24,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"dff7cd81-b9c1-43d9-f5d9-e1966ca2c5b0"},"source":["PATH = os.path.join(\"drive\", \"My Drive\", \"Colab Notebooks\", \"GEN\") \n","\n","sys.path.append(PATH+'/biomatsim')\n","from dataset.data_loader_synthetic import ToyCell, ToyCellpair\n","from model_vae_synthetic import VAE\n","from model_qzfreg_synthetic import QZFREG\n","from model_main_synthetic import FDVAE, REGVAE, Discriminator\n","from diva.pixel_cnn_utils import sample\n","\n","print(torch.cuda.is_available())"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","metadata":{"id":"7BgvadnFgnaG","executionInfo":{"status":"ok","timestamp":1635263116075,"user_tz":-180,"elapsed":23,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary\n","##########################\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","##########################"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tXE_ntmpUtA"},"source":["### Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TB0HzysEy2mO","executionInfo":{"status":"ok","timestamp":1635263116076,"user_tz":-180,"elapsed":23,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"cdfc9dab-92aa-4318-f1ea-7e8ca8ec9c2b"},"source":["# get topography data\n","dataset_name = 'pdata1_128'\n","\n","if not os.path.isdir('pdata1_128'): \n","  start_time = time.time()\n","  if not os.path.isfile('pdata1_128.zip'): \n","    ! wget -O pdata1_128.zip \"https://surfdrive.surf.nl/files/index.php/s/QrMeUvt9ZPIOKnP/download\"\n","  ! unzip -q pdata1_128.zip -d .\n","  print(\"Unzipped.\")\n","  print(\"Elapsed time: {} seconds.\".format(time.time()-start_time))\n","else:\n","  print('Found folder pdata1_128')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found folder pdata1_128\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuNcHUxtpiPI","executionInfo":{"status":"ok","timestamp":1635263116076,"user_tz":-180,"elapsed":19,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"47333090-fd1b-42b5-901f-3cc6b201bdc3"},"source":["# get cell data\n","dataset_name = 'dataset2_128_fixloc_1scale'\n","\n","if not os.path.isdir('dataset2_128_fixloc_1scale'):\n","  start_time = time.time()\n","  if not os.path.isfile('dataset2_128_fixloc_1scale.zip'): \n","    ! wget -O dataset2_128_fixloc_1scale.zip \"https://surfdrive.surf.nl/files/index.php/s/VuU2UKuHlBpvxgh/download\"\n","  ! unzip -q dataset2_128_fixloc_1scale.zip -d .\n","  print(\"Unzipped.\")\n","  print(\"Elapsed time: {} seconds.\".format(time.time()-start_time))\n","else:\n","  print('Found folder dataset2_128_fixloc_1scale')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Found folder dataset2_128_fixloc_1scale\n"]}]},{"cell_type":"markdown","metadata":{"id":"UDVkDQCuU8Mr"},"source":["### Initialize FDVAE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGqnMKxuVBtj","executionInfo":{"status":"ok","timestamp":1635263116077,"user_tz":-180,"elapsed":16,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"6344e59a-1a85-447f-90ae-33cf58c13a7e"},"source":["model_name_fdvae = 'FDVAE_seed_1_zdims_222_2_v1'  #_epoch_20'\n","model_path_fdvae = PATH+'/model_output_synthetic/fdvae/' + model_name_fdvae\n","\n","print(model_name_fdvae)\n","print(model_path_fdvae)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["FDVAE_seed_1_zdims_222_2_v1\n","drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/fdvae/FDVAE_seed_1_zdims_222_2_v1\n"]}]},{"cell_type":"code","metadata":{"id":"hUYI925Rj4B7","executionInfo":{"status":"ok","timestamp":1635263116078,"user_tz":-180,"elapsed":14,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["with open(model_path_fdvae + '/' + model_name_fdvae +\\\n","          '.json', 'r') as configfile:\n","    args_fdvae = json.load(configfile)\n","args_fdvae = dotdict(args_fdvae)\n","\n","args_fdvae.cuda = not args_fdvae.no_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if args_fdvae.cuda else \"cpu\")\n","kwargs = {'num_workers': 4, 'pin_memory': False} if args_fdvae.cuda else {}\n","\n","# Set seed\n","torch.manual_seed(1)\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(args_fdvae.seed)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvOYFkQlkAL8","executionInfo":{"status":"ok","timestamp":1635263116575,"user_tz":-180,"elapsed":2,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["model_fdvae = torch.load(model_path_fdvae + '/' + model_name_fdvae + '_epoch_2' + '.model')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MFVsnsCj59D","executionInfo":{"status":"ok","timestamp":1635263117045,"user_tz":-180,"elapsed":7,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"c440e589-dd6e-4164-c24e-8ee20cbbcf79"},"source":["def nparams(module):\n","    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","nparams(model_fdvae)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2678167"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovOOuFmujzdD","executionInfo":{"status":"ok","timestamp":1635263117564,"user_tz":-180,"elapsed":6,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"a44c545a-cbf0-4fbf-fde7-8f6c0a74a661"},"source":["# freeze fully\n","for name, p in model_fdvae.named_parameters():\n","    p.requires_grad = False\n","\n","nparams(model_fdvae)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"FvTrT-iwgnaL"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"wOh8OnSVad6o","executionInfo":{"status":"ok","timestamp":1635263118534,"user_tz":-180,"elapsed":2,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["def save_reconstructions_lx1(model, l, x, path=''):\n","    \"\"\"\n","    Generate a cell image based on a topography image. 8 examples.\n","    zeps is sampled from prior (simulation of experiment; actual application scenario).\n","    N.B. At training zeps is sampled from the posterior q(ze|x) (Training scheme 2Ax)\n","    \"\"\"\n","    with torch.no_grad():\n","        x = x[:8]\n","        l = l[:8]\n","        x_recon, _, _, _, _, _, _, _, _, _ = model.forward_lx(l)\n","        sample_t = sample(x_recon)\n","\n","        comparison = torch.cat([l, sample_t])\n","        save_image(comparison.cpu(),\n","                   path + 'reconstruction_lx1_' + str(epoch-1) + '.png', nrow=8)\n","\n","def save_reconstructions_lx1_same(model, l, x, path='', n=2):\n","    \"\"\"\n","    Generate 8 cell images based on a single topography image. \n","    zeps is sampled from prior (simulation of experiment; actual application scenario).\n","    N.B. At training zeps is sampled from the posterior q(ze|x) (Training scheme 2Ax)\n","    \"\"\"\n","    with torch.no_grad():\n","        x_rep = x[:n].repeat_interleave(8, dim=0)\n","        l_rep = l[:n].repeat_interleave(8, dim=0)    \n","    \n","        x_recon, _, _, _, _, _, _, _, _, _ = model.forward_lx(l_rep)\n","        sample_t = sample(x_recon)\n","\n","        for i in range(n):\n","            comparison = torch.cat([l_rep[i*8:(i+1)*8], sample_t[i*8:(i+1)*8]])\n","            save_image(comparison.cpu(),\n","                    path + 'reconstruction_lx1_same_' + str(epoch-1) + f'{i}.png', nrow=8)\n","\n","def save_reconstructions_l(model, l, path=''):\n","    \"\"\"\n","    Topography image reconstruction. 8 examples.\n","    \"\"\"\n","    with torch.no_grad():\n","        l = l[:8]\n","        l_recon, _, _, _, _, _, _, _, _, _, _, _, _ = model.forward_l(l)\n","        sample_t = sample(l_recon)\n","\n","        comparison = torch.cat([l, sample_t])\n","        save_image(comparison.cpu(),\n","                   path + 'reconstruction_l_' + str(epoch-1) + '.png', nrow=8)\n","\n","\n","def save_reconstructions_xl(model, l, x, path=''):\n","    \"\"\"\n","    Generate a topography image based on a cell image. 8 examples.\n","    Training scheme 2Bp - l_eps sampled from posterior q(le|p) (not used).\n","    \"\"\"\n","    with torch.no_grad():\n","        x = x[:8]\n","        l = l[:8]\n","        l_recon2, _, _, _, _, _, _, _, _, _ = model.forward_xl(l, x)\n","        sample_t = sample(l_recon2)\n","\n","        comparison = torch.cat([x, sample_t])\n","        save_image(comparison.cpu(),\n","                   path + 'reconstruction_xl_' + str(epoch-1) + '.png', nrow=8)\n","\n","def save_reconstructions_xl_prior(model, l, x, path=''):\n","    \"\"\"\n","    Generate a topography image based on a cell image.\n","    Training scheme 2B (used by default) - l_eps sampled from prior.\n","    Actual application scenario for cell image-conditioned topography generation.\n","    \"\"\"\n","    # Save reconstuction\n","    with torch.no_grad():\n","        x = x[:8]\n","        l = l[:8]\n","        l_recon2, _, _, _, _, _, _, _, _, _ = model.forward_xl_prior(l, x)\n","        sample_t = sample(l_recon2)\n","\n","        comparison = torch.cat([x, sample_t])\n","        save_image(comparison.cpu(),\n","                   path + 'reconstruction_xlp_' + str(epoch-1) + '.png', nrow=8)\n","        \n","def save_reconstructions_xl_prior_same(model, l, x, path='', n=2):\n","    \"\"\"\n","    Generate 8 topography images for a sinlge cell image. \n","    Training scheme 2B (used by default) - l_eps sampled from prior.\n","    Actual application scenario for cell image-conditioned topography generation.\n","    \"\"\"\n","    with torch.no_grad():\n","        # x = x[:8]\n","        # l = l[:8]\n","        x_rep = x[:n].repeat_interleave(8, dim=0)\n","        l_rep = l[:n].repeat_interleave(8, dim=0)\n","        l_recon2, _, _, _, _, _, _, _, _, _ = model.forward_xl_prior(l_rep, x_rep)\n","        sample_t = sample(l_recon2)\n","\n","        for i in range(n):\n","          comparison = torch.cat([x_rep[i*8:(i+1)*8], sample_t[i*8:(i+1)*8]])\n","          save_image(comparison.cpu(),\n","                    path + 'reconstruction_xlp_' + str(epoch-1) + f'{i}.png', nrow=8)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"QexQpUx4l4fx","executionInfo":{"status":"ok","timestamp":1635263120583,"user_tz":-180,"elapsed":381,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["\"\"\"\n","l ----TRAIN qzeps qzf_list ----> ze/zf/(le) --freeze--> x'\n","\"\"\"\n","def run_epoch_lx(data_loader, model, optimizer, epoch, rec_freq=None, path_reconstructions='', train=True):\n","    #model.train()\n","    avg_loss = 0\n","    ce_x = 0\n","    d_qzx_pzx = 0\n","    kl_zeps = 0\n","    kls_zfk = [0] * model.fdvae.num_features\n","\n","    for batch_idx, (l, fl, x, fx) in tqdm(enumerate(data_loader)):\n","        l = l.to(device)\n","        x = x.to(device)\n","\n","        if train and rec_freq and (epoch % rec_freq == 0) and (batch_idx == 1):\n","            model.eval()\n","            #save_reconstructions_lx(model, l, x, path_reconstructions)  # [x, sample_x]\n","            save_reconstructions_lx1(model, l, x, path_reconstructions)  # [l, sample_x]\n","            save_reconstructions_lx1_same(model, l, x, path_reconstructions)  # [l, sample_x]\n","\n","        if train: \n","          model.train()\n","          optimizer.zero_grad()\n","          loss, CE_x, D_qzx_pzx, KL_zeps, KLs_zfk = model.loss_function_x(l, x)  #l ----TRAIN qzeps qzf_list ----> ze/zf/(le) --freeze--> x'\n","          loss.backward()\n","          optimizer.step()\n","        else:\n","          with torch.no_grad():\n","            loss, CE_x, D_qzx_pzx, KL_zeps, KLs_zfk = model.loss_function_x(l, x)  #l ----TRAIN qzeps qzf_list ----> ze/zf/(le) --freeze--> x'\n","\n","        avg_loss += loss.item()\n","        ce_x += CE_x.item()\n","        d_qzx_pzx += D_qzx_pzx.item()\n","        kl_zeps += KL_zeps#.item()\n","        for k in range(model.fdvae.num_features):\n","            kls_zfk[k] += KLs_zfk[k].item()\n","\n","    avg_loss /= len(data_loader.dataset)\n","    ce_x /= len(data_loader.dataset)\n","    d_qzx_pzx /= len(data_loader.dataset)\n","    kl_zeps /= len(data_loader.dataset)\n","    for k in range(model.fdvae.num_features):\n","        kls_zfk[k] /= len(data_loader.dataset)\n","\n","    return avg_loss, ce_x, d_qzx_pzx, kl_zeps, kls_zfk"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5V2aMNUm9WF","executionInfo":{"status":"ok","timestamp":1635263122311,"user_tz":-180,"elapsed":2,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["\"\"\"\n","MAIN OBJECTIVE:\n","l ---freeze---------> ze/zf/---\n","l ---TRAIN qleps ---> le -------TRAIN pl---> l'\n","\n","REGULARIZE (loss * self.eta):\n","x ---freeze (fdvae) --> ze/zf/---\n","l ---TRAIN qleps------> le -----TRAIN pl---> l'  \n","\"\"\"\n","\n","def run_epoch_l(data_loader, model, optimizer, epoch, with_x=True, rec_freq=None, path_reconstructions='', train=True):\n","    #model.train()\n","    avg_loss = 0\n","    ce_l = 0\n","    ce_l2 = 0\n","    kl_zeps = 0\n","    kl_leps = 0\n","    kls_zfk = [0] * model.fdvae.num_features\n","    kl_combined = 0\n","    kl_combined2 = 0\n","\n","    for batch_idx, out in tqdm(enumerate(data_loader)):\n","        if with_x:\n","          l = out[0].to(device)  # l, fl, x, fx\n","          x = out[2].to(device)\n","        else:\n","           l = out[0].to(device)  # l, fl, x, fx\n","\n","        if train and rec_freq and (epoch % rec_freq == 0) and (batch_idx == 1):\n","            model.eval()\n","            save_reconstructions_l(model, l, path_reconstructions)\n","            #save_reconstructions_xl(model, l, x, path_reconstructions)\n","            save_reconstructions_xl_prior(model, l, x, path_reconstructions)\n","            save_reconstructions_xl_prior_same(model, l, x, path_reconstructions)\n","\n","        if train: \n","          model.train()\n","          optimizer.zero_grad()\n","          if with_x:\n","            loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l, x)\n","          else:\n","            loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l)  # this is only for the case when we don't want to use the regularizer\n","          loss.backward()\n","          optimizer.step()\n","        else:\n","          with torch.no_grad():\n","            if with_x:\n","              loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l, x)\n","            else:\n","              loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l)  # this is only for the case when we don't want to use the regularizer\n","\n","        avg_loss += loss.item()\n","        ce_l += CE_l.item()\n","        ce_l2 += CE_l2.item()\n","        kl_zeps += KL_zeps#.item()\n","        kl_leps += KL_leps.item()\n","        for k in range(model.fdvae.num_features):\n","            kls_zfk[k] += KLs_zfk[k].item()\n","        kl_combined += KL_combined.item()\n","        kl_combined2 += KL_combined2.item()\n","\n","    avg_loss /= len(data_loader.dataset)\n","    ce_l /= len(data_loader.dataset)\n","    ce_l2 /= len(data_loader.dataset)\n","    kl_zeps /= len(data_loader.dataset)\n","    kl_leps /= len(data_loader.dataset)\n","    for k in range(model.fdvae.num_features):\n","        kls_zfk[k] /= len(data_loader.dataset)\n","    kl_combined /= len(data_loader.dataset)\n","    kl_combined2 /= len(data_loader.dataset)\n","\n","    return avg_loss, ce_l, ce_l2, kl_zeps, kl_leps, kls_zfk, kl_combined, kl_combined2"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Blkx5icfgnaU"},"source":["Setting the parameters REGVAE"]},{"cell_type":"code","metadata":{"id":"vrs9smSMgnaV","executionInfo":{"status":"ok","timestamp":1635263124202,"user_tz":-180,"elapsed":590,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# REGVAE\n","args = {\n","    'no_cuda': False, \n","    'seed': 1, \n","    'batch_size': 50,  # 20,\n","    'epochs': 500,\n","    'lr': 0.01,\n","\n","    # data info\n","    'path_l': 'pdata1_128/',\n","    'path_x': 'dataset2_128_fixloc_1scale/',\n","    'path_table': 'pdata1_128/', # 'pdata1_128/' ?\n","    'data_info_filename': 'pdata1_dataset2_w1000_reg2.csv', #'pdata1_dataset2_control.csv', #'pdata1_dataset2_w1000_reg2.csv'\n","    'features_names_l': ['roundness_g1', 'radius_g2'],\n","    'features_names_x': ['roundness_f1', 'elongation_f2', 'nucleus_size_f3'],  # 'rotation_angle_f4'\n","\n","    # Model REGVAE\n","    'fdvae': model_fdvae,\n","    'leps_dim': 2, \n","    'use_zeps': False,  # ! (not used by default)\n","    \n","    # Beta VAE part \n","    'lbetas_f': [300, 300, 300],\n","    'lbeta_eps': 400,  # for z_eps as part of the topography latent space; used only if self.use_zeps (not used by default)\n","    'beta_leps': 500,\n","    ## https://arxiv.org/abs/1804.03599 approach for l_eps to control the capacity of the latent space\n","    'gamma_leps': 0,  # beta_eps is used when gamma = 0\n","    'c_leps': 3,  # warmup for c\n","    ##\n","    'prior_leps_scale_train': False, #True,\n","    'eta': 0.5,  # weight of the 'cell-conditioned topography design' objective\n","\n","    ######### NOT USED\n","    # LH * (D + delta) - True; LH - False\n","    'kl_llh_multiplier': False, \n","    'delta': 10,  # for CE_l(x_recon, x) * (KL + delta), where ze ~ q(ze|l), zf ~ q(zf|l)\n","    #########\n","\n","    # not used\n","    'beta_combined': 0,\n","    'beta_combined2': 0,\n","\n","    # warm-up (?)\n","    'w': 20,  #100,  # 'number of epochs for warm-up.\n","    'max_beta': 1.,  # 'max beta for warm-up'\n","    'min_beta': 0.,\n","\n","    'outpath': PATH+'/model_output_synthetic/regvae',  #'./'    \n","}\n","\n","args = dotdict(args)\n","args.cuda = not args.no_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","kwargs = {'num_workers': 0, #1,   # https://github.com/pytorch/pytorch/issues/5301\n","          'pin_memory': False} if args.cuda else {}"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCOb2HuEp0eI","executionInfo":{"status":"ok","timestamp":1635263125738,"user_tz":-180,"elapsed":8,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"70b8c733-4f5e-4ea8-f9a1-5dd1ef913d8f"},"source":["##### Model name\n","model_name = 'REGVAE_seed_' + str(args.seed) + '_main_betas300_v1'  # or control dataset\n","\n","model_path = args.outpath + '/' + model_name\n","print(args.outpath)\n","print(model_name)\n","print(model_path)\n","\n","# Set seed\n","torch.manual_seed(args.seed)\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(args.seed)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae\n","REGVAE_seed_1_main_betas300_v1\n","drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae/REGVAE_seed_1_main_betas300_v1\n"]}]},{"cell_type":"markdown","metadata":{"id":"nGSVkLJGqD7S"},"source":["# ----------------------"]},{"cell_type":"markdown","metadata":{"id":"nN55ROnRqD3X"},"source":["Data loader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdMEWstgqdds","executionInfo":{"status":"ok","timestamp":1635263135842,"user_tz":-180,"elapsed":9135,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"38aa7769-54b4-403f-9b08-c1f89269c9b2"},"source":["data_info_table = pd.read_csv(args.path_table + args.data_info_filename, index_col=0)\n","\n","###\n","np.random.seed(1)\n","img_list_x_val = list(np.random.choice(data_info_table['filename_x'].values, int(round(data_info_table.shape[0] * 0.2)), replace=False))\n","img_list_x_train = [img for img in data_info_table['filename_x'].values if img not in img_list_x_val]\n","\n","print(len(img_list_x_train), len(img_list_x_val))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["32627 10000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgVEcRh4qdX5","executionInfo":{"status":"ok","timestamp":1635263238229,"user_tz":-180,"elapsed":102406,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"25567e30-c112-43a2-fce6-d78b70c777c5"},"source":["train_data = ToyCellpair(path_l=args.path_l, \n","                         path_x=args.path_x, # + \"*\",\n","                         path_table=args.path_table,\n","                         data_info_filename=args.data_info_filename, \n","                         features_names_l=args.features_names_l,\n","                         features_names_x=args.features_names_x,\n","                         imgsize=(128, 128),\n","                         # condition_l=\"00[3-5]*\" # \"00[0-2]*\",  ##\"00[0]*\"#\"000*\",\n","                         img_list_x=img_list_x_train,\n","                         scaler=True\n","                         )\n","train_loader = data_utils.DataLoader(train_data, batch_size=args.batch_size, shuffle=True, **kwargs)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","100%|██████████| 32627/32627 [00:40<00:00, 814.41it/s]\n","100%|██████████| 32627/32627 [00:55<00:00, 584.73it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unlfIrVuq6lw","executionInfo":{"status":"ok","timestamp":1635263259969,"user_tz":-180,"elapsed":21755,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"a5e3bca7-3bfb-4d3f-c9a0-0e7852a990df"},"source":["val_data = ToyCellpair(path_l=args.path_l, \n","                       path_x=args.path_x, # + \"*\",\n","                       path_table=args.path_table,\n","                       data_info_filename=args.data_info_filename, \n","                       features_names_l=args.features_names_l,\n","                       features_names_x=args.features_names_x,\n","                       imgsize=(128, 128),\n","                       condition_x=\"00[3-5]*\",         # \"00[0-2]*\",  ##\"00[0]*\"#\"000*\",  ### take part of the data to reduce gpu usage\n","                       img_list_x=img_list_x_val,\n","                       scaler=True\n","                       )\n","val_loader = data_utils.DataLoader(val_data, batch_size=args.batch_size, shuffle=True, **kwargs)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","100%|██████████| 6933/6933 [00:10<00:00, 683.72it/s]\n","100%|██████████| 6933/6933 [00:10<00:00, 670.69it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"dfS50qjkSXPC"},"source":["# set([el.split(\"/\")[1] for el in train_data.final_filenames_x]).intersection(set([el.split(\"/\")[1] for el in val_data.final_filenames_x])) # set()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VdVRLxBRqRVW"},"source":["# ---------------------"]},{"cell_type":"markdown","metadata":{"id":"f-ZcqCVYgnaZ"},"source":["### Setup the model"]},{"cell_type":"markdown","metadata":{"id":"NAUxjEG4sa9r"},"source":["Step 2"]},{"cell_type":"code","metadata":{"id":"yZ_pDn1pF6IG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635259649753,"user_tz":-180,"elapsed":450,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"b46b7585-4bdf-43e4-cdd0-283383f2baf7"},"source":["######## REGVAE (STEP2: training the zf encoders of the topography model)\n","# setup the VAE\n","model = REGVAE(args).to(device)\n","##\n","model.fdvae = model_fdvae\n","##\n","model = model.cuda()\n","\n","print(nparams(model))\n","\n","# check \n","print(model.lqzf_list[0].fc11[0].weight.requires_grad)\n","print(model.fdvae.qzf_list[0].fc11[0].weight.requires_grad)\n","\n","# list(model.state_dict().keys())\n","####################################################\n","\n","# STEP 1:  freeze qle, pl, train lqzf_list\n","for name, child in model.named_children():\n","  print(name)\n","  if name in ['pl', 'qleps']:\n","    for p in child.parameters():\n","      p.requires_grad = False\n","\n","model.prior_leps_log_scale.requires_grad = False  # relevant when prior_leps_scale_train == True\n","\n","print(nparams(model))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2678122\n","True\n","False\n","fdvae\n","pl\n","qleps\n","lqzf_list\n","1672620\n"]}]},{"cell_type":"code","metadata":{"id":"xpp6sryMsXIQ"},"source":["############ MORE TRAINING\n","# model = torch.load(model_path + '/' + model_name + '_epoch_10' + '.model')#, map_location=torch.device('cpu'))\n","# model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98RLUTbssZjM"},"source":["############ INITIALIZE FROM ANOTHER MODEL\n","# base_model_name = 'REGVAE_seed_1_main_betas300_v0'\n","# base_model_path = 'drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae/REGVAE_seed_1_main_betas300_v0'\n","# model = torch.load(base_model_path + '/' + base_model_name + '_epoch_20' + '.model')#, map_location=torch.device('cpu'))\n","# model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uOugWAN0sg3o"},"source":["Step 3"]},{"cell_type":"code","metadata":{"id":"9rgDJ9YuGKWG","executionInfo":{"status":"ok","timestamp":1635260090665,"user_tz":-180,"elapsed":469,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["######## Load the model trained in the previous step.\n","model = torch.load(model_path + '/' + model_name + '_epoch_1' + '.model')#, map_location=torch.device('cpu'))\n","model = model.to(device)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsL6Hrv3sh2I"},"source":["######## Load the model trained in the previous step.\n","# base_model_name = 'REGVAE_seed_1_main_betas300_v0'\n","# base_model_path = 'drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae/REGVAE_seed_1_main_betas300_v0'\n","# model = torch.load(base_model_path + '/' + base_model_name + '_epoch_20' + '.model')#, map_location=torch.device('cpu'))\n","# model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yf1e3AWkM3x5","executionInfo":{"status":"ok","timestamp":1635260095969,"user_tz":-180,"elapsed":399,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"e74d8e7a-9575-4c4b-ac74-229af052f841"},"source":["######## REGVAE (STEP3: training the remaining components of the topography model: qle, pl; freeze lqzf_list)\n","for name, child in model.named_children():\n","  print(name)\n","  if name in ['pl', 'qleps']:\n","    for p in child.parameters():\n","      p.requires_grad = True\n","  if name in ['lqzf_list']:\n","    for p in child.parameters():\n","      p.requires_grad = False\n","\n","model.prior_leps_log_scale.requires_grad = True  # # relevant when prior_leps_scale_train == True"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["fdvae\n","pl\n","qleps\n","lqzf_list\n"]}]},{"cell_type":"code","metadata":{"id":"wgn_Iut8nsmU"},"source":["##################################### Some notes on differents regimes of training \n","# ###Here we only train qleps and pl.fc1\n","# ########## ! now freeze pl (except fc1) and train only qleps\n","# for name, child in model.named_children():\n","#   if name in ['pl']:#['pzf_list', 'qzf_list', 'qf_list', 'prior_zf_full_log_scales']:\n","#     for name1, child1 in child.named_children():\n","#       if name1 != 'fc1':  # fc1 True\n","#         print(name1)\n","#         for p in child1.parameters():\n","#           p.requires_grad = False\n","\n","#######\n","# # we train ONLY pl, including fc1. qleps is frozen\n","# print('activate pl except pl.fc1')\n","# for name, child in model.named_children():\n","#   if name in ['pl']:#['pzf_list', 'qzf_list', 'qf_list', 'prior_zf_full_log_scales']:\n","#     for name1, child1 in child.named_children():\n","#     ###if name1 != 'fc1':  # disable for train_pl\n","#       print(name1)\n","#       for p in child1.parameters():\n","#         p.requires_grad = True ### we also train fc1 !!!\n","\n","# # print('disable qzeps, px.fc1')\n","# for name, child in model.named_children():\n","#   if name in ['qleps']:#['pzf_list', 'qzf_list', 'qf_list', 'prior_zf_full_log_scales']:\n","#     for name1, child1 in child.named_children():\n","#       print(name1)\n","#       for p in child1.parameters():\n","#         p.requires_grad = False\n","\n","# ###for p in model.pl.fc1.parameters():   # let's also train fc1\n","# ###   p.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJNf66OTtdLY"},"source":["# ---------------------\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7C_VNODxL_T2","executionInfo":{"status":"ok","timestamp":1635260099956,"user_tz":-180,"elapsed":4,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"68fd8de7-f834-4ef2-bcba-720879546760"},"source":["# check \n","print(model.qleps.conv1.weight.requires_grad)\n","print(model.lqzf_list[0].fc11[0].weight.requires_grad)\n","print(model.fdvae.qzf_list[0].fc11[0].weight.requires_grad)\n","print(model.pl.conv1.weight.requires_grad)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n","False\n","True\n"]}]},{"cell_type":"markdown","metadata":{"id":"UuxK8rcyEnkl"},"source":["# ---------------------\n"]},{"cell_type":"markdown","metadata":{"id":"lbBni6J9tlu1"},"source":["Setup the optimizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5wDJIdqwy6m","executionInfo":{"status":"ok","timestamp":1635260107909,"user_tz":-180,"elapsed":680,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"8e36820d-8f05-4f68-a744-b1fa6622f969"},"source":["print(args.lr)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["0.01\n"]}]},{"cell_type":"code","metadata":{"id":"_7HzFyG8tobR","executionInfo":{"status":"ok","timestamp":1635260108420,"user_tz":-180,"elapsed":5,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# args.lr = 0.001"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oepk4XomisD8","executionInfo":{"status":"ok","timestamp":1635260110936,"user_tz":-180,"elapsed":534,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n","\n","best_loss = 1e+8\n","best_y_acc = 0.\n","\n","early_stopping_counter = 1\n","max_early_stopping = 100"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pn_Xz6YwyWb0"},"source":["# ---------------------"]},{"cell_type":"code","metadata":{"id":"RYXgd-Lkk56R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635260112393,"user_tz":-180,"elapsed":4,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"1e4e223a-f9c3-4807-c5d7-603f329d0f1c"},"source":["# check the arguments\n","{i:args[i] for i in args if i!='fdvae'}"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'batch_size': 50,\n"," 'beta_combined': 0,\n"," 'beta_combined2': 0,\n"," 'beta_leps': 500,\n"," 'c_leps': 3,\n"," 'cuda': True,\n"," 'data_info_filename': 'pdata1_dataset2_w1000_reg2.csv',\n"," 'delta': 10,\n"," 'epochs': 500,\n"," 'eta': 0.5,\n"," 'features_names_l': ['roundness_g1', 'radius_g2'],\n"," 'features_names_x': ['roundness_f1', 'elongation_f2', 'nucleus_size_f3'],\n"," 'gamma_leps': 0,\n"," 'kl_llh_multiplier': False,\n"," 'lbeta_eps': 400,\n"," 'lbetas_f': [300, 300, 300],\n"," 'leps_dim': 2,\n"," 'lr': 0.01,\n"," 'max_beta': 1.0,\n"," 'min_beta': 0.0,\n"," 'no_cuda': False,\n"," 'outpath': 'drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae',\n"," 'path_l': 'pdata1_128/',\n"," 'path_table': 'pdata1_128/',\n"," 'path_x': 'dataset2_128_fixloc_1scale/',\n"," 'prior_leps_scale_train': False,\n"," 'seed': 1,\n"," 'use_zeps': False,\n"," 'w': 20}"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJYZ339ak21N","executionInfo":{"status":"ok","timestamp":1635260114923,"user_tz":-180,"elapsed":621,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"49f55944-74a2-410f-c412-55e22e4d7cc1"},"source":["model_name, model_path"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('REGVAE_seed_1_main_betas300_v1',\n"," 'drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/regvae/REGVAE_seed_1_main_betas300_v1')"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"zK43Xkfgk4gH","executionInfo":{"status":"ok","timestamp":1635259692257,"user_tz":-180,"elapsed":419,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["os.mkdir(model_path)\n","\n","import json\n","\n","with open(model_path + '/' + model_name + '.json', 'w') as configfile:\n","    json.dump({i:args[i] for i in args if i!='fdvae'}, configfile, indent=2)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpB8xEoJvG8H","executionInfo":{"status":"ok","timestamp":1635260116236,"user_tz":-180,"elapsed":7,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"f693f542-8ad2-4879-fcd5-f66688dc1c15"},"source":["def nparams(module):\n","    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","nparams(model)"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1005502"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"8wv_pQR2t-38"},"source":["# -------------------------"]},{"cell_type":"markdown","metadata":{"id":"gk4vblzhuAVB"},"source":["TRAINING -- STEP 2"]},{"cell_type":"code","metadata":{"id":"tp94Ps1buGcS"},"source":["# check\n","# model.lbetas_f, args.lbetas_f "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqQRExeTuKii"},"source":["# check\n","# model.use_zeps"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIfDqa4haOaX","executionInfo":{"status":"ok","timestamp":1635259697144,"user_tz":-180,"elapsed":509,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["import copy\n","args_COPY = copy.deepcopy(dict(args))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"SohkwCnLFAEd"},"source":["######## Training loop REGVAE - STEP 2\n","print('\\nStart training [[[STEP 2]]]:', {i:args[i] for i in args if i!='fdvae'})\n","for epoch in range(1, args.epochs + 1):\n","\n","    ######################################\n","    ### WARMUP (increase beta gradually).\n","    ### Formula: min([final_value, curent_val + (final value - current_val) * (epoch * 1. - epochs_completed) / (args_COPY['w'] - epochs_completed)])\n","    #model.beta_leps = min([args_COPY['beta_leps'], 0 + (args_COPY['beta_leps'] - 0) * (epoch * 1. - 0) / (args_COPY['w'] - 0)])\n","    # for k in range(model.fdvae.num_features):\n","    #     model.lbetas_f[k] = min([args_COPY['lbetas_f'][k], 0 + (args_COPY['lbetas_f'][k] - 0) * (epoch * 1.) / (args_COPY['w'] - 0)])\n","    # print('BETAS: ', model.beta_leps, model.lbetas_f, args_COPY['beta_leps'], args_COPY['lbetas_f'])\n","    ######################################\n","\n","    # Train\n","    train_loss, ce_x, d_qzx_pzx, kl_zeps, kls_zfk = run_epoch_lx(train_loader, model, optimizer, epoch, \n","                                                                 rec_freq=1, path_reconstructions=model_path + '/', train=True)\n","\n","    # logging train scores\n","    str_print = \"{} EPOCH: avg loss {}\".format(epoch, train_loss)\n","    str_print += f\" avg ce_x {ce_x}\"\n","    str_print += f\" avg D {d_qzx_pzx}\"\n","    str_print += f\" avg KL_eps {kl_zeps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {kls_zfk[k]}\"\n","    print(str_print)\n","\n","    # Val\n","    val_loss, val_ce_x, val_d_qzx_pzx, val_kl_zeps, val_kls_zfk = run_epoch_lx(val_loader, model, optimizer, epoch, \n","                                                                               rec_freq=1, path_reconstructions=model_path + '/', train=False)\n","\n","    # logging val scores\n","    str_print = \"{} EPOCH: VAL avg loss {}\".format(epoch, val_loss)\n","    str_print += f\" avg ce_x {val_ce_x}\"\n","    str_print += f\" avg D {val_d_qzx_pzx}\"\n","    str_print += f\" avg KL_eps {val_kl_zeps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {kls_zfk[k]}\"\n","    print(str_print)\n","\n","    if val_loss < best_loss:\n","        early_stopping_counter = 1\n","\n","        best_loss = val_loss\n","\n","        print(\"saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","        torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","    else:\n","        #######\n","        if epoch >= 1 and epoch % 10 == 0:\n","            print(\"RESERVE saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","            torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","        #######   \n","        early_stopping_counter += 1\n","        if early_stopping_counter == max_early_stopping:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LBWuFUMwoBS"},"source":["# 653it [03:50,  2.83it/s]\n","# 1 EPOCH: avg loss 208956.9319888436 avg ce_x 201253.2048610047 avg D 25.879229548136237 avg KL_eps 0.0 \n","# , roundness_f1 KL 4.301376469600693, elongation_f2 KL 4.7941591136136275, nucleus_size_f3 KL 16.583553050324113\n","# 139it [00:17,  8.17it/s]\n","# 1 EPOCH: VAL avg loss 207863.5752308136 avg ce_x 202214.06073283323 avg D 19.032232664254657 avg KL_eps 0.0 \n","# , roundness_f1 KL 4.301376469600693, elongation_f2 KL 4.7941591136136275, nucleus_size_f3 KL 16.583553050324113\n","# saving model:  REGVAE_seed_1_main_betas300_v1_epoch_1.model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWHOswS1wN3t"},"source":["# -------------------------"]},{"cell_type":"markdown","metadata":{"id":"o9L_9N8EOZZW"},"source":["TRAINING -- STEP3"]},{"cell_type":"code","metadata":{"id":"JZcrId1AGU29","executionInfo":{"status":"ok","timestamp":1635260127734,"user_tz":-180,"elapsed":460,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["import copy\n","args_COPY = copy.deepcopy(dict(args))"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"seTl-GnjG6zi"},"source":["######## Training loop REGVAE - STEP 3\n","print('\\nStart training [[[STEP 3]]]:', {i:args[i] for i in args if i!='fdvae'})\n","for epoch in range(1, args.epochs + 1):\n","\n","    ######################################\n","    ### WARMUP (increase beta gradually).\n","    ### Formula: min([final_value, curent_val + (final value - current_val) * (epoch * 1. - epochs_completed) / (args_COPY['w'] - epochs_completed)])\n","    #model.beta_leps = min([args_COPY['beta_leps'], 0 + (args_COPY['beta_leps'] - 0) * (epoch * 1. - 0) / (args_COPY['w'] - 0)])\n","    # for k in range(model.fdvae.num_features):\n","    #     model.lbetas_f[k] = min([args_COPY['lbetas_f'][k], 0 + (args_COPY['lbetas_f'][k] - 0) * (epoch * 1.) / (args_COPY['w'] - 0)])\n","    # print('BETAS: ', model.beta_leps, model.lbetas_f, args_COPY['beta_leps'], args_COPY['lbetas_f'])\n","    ######################################\n","\n","    # Train\n","    train_loss, ce_l, ce_l2, kl_zeps, \\\n","      kl_leps, kls_zfk, kl_combined, kl_combined2 = run_epoch_l(train_loader, model, optimizer, epoch, with_x=True, \n","                                                                rec_freq=1, path_reconstructions=model_path + '/', train=True)\n","\n","    # logging train scores\n","    str_print = \"{} EPOCH: avg loss {}\".format(epoch, train_loss)\n","    str_print += f\" avg ce_l {ce_l}\"\n","    str_print += f\" avg ce_l2 {ce_l2}\"\n","    str_print += f\" avg KL_eps {kl_zeps}\"\n","    str_print += f\" avg KL_leps {kl_leps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {kls_zfk[k]}\"\n","    str_print += f\"\\n avg KL_combined {kl_combined}\"\n","    str_print += f\" avg KL_combined2 {kl_combined2}\"\n","    print(str_print)\n","\n","    # Val\n","    val_loss, val_ce_l, val_ce_l2, val_kl_zeps, \\\n","      val_kl_leps, val_kls_zfk, val_kl_combined, val_kl_combined2 = run_epoch_l(val_loader, model, optimizer, epoch, with_x=True, \n","                                                                                rec_freq=1, path_reconstructions=model_path + '/', train=False)\n","\n","    # logging val scores\n","    str_print = \"{} EPOCH: VAL avg loss {}\".format(epoch, val_loss)\n","    str_print += f\" avg ce_l {val_ce_l}\"\n","    str_print += f\" avg ce_l2 {val_ce_l2}\"\n","    str_print += f\" avg KL_eps {val_kl_zeps}\"\n","    str_print += f\" avg KL_leps {val_kl_leps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {val_kls_zfk[k]}\"\n","    str_print += f\"\\n avg KL_combined {val_kl_combined}\"\n","    str_print += f\" avg KL_combined2 {val_kl_combined2}\"\n","    print(str_print)\n","\n","    if val_loss < best_loss:\n","        early_stopping_counter = 1\n","\n","        best_loss =  val_loss\n","\n","        print(\"saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","        torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","    else:\n","        #######\n","        if epoch >= 1 and epoch % 10 == 0:\n","            print(\"RESERVE saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","            torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","        #######   \n","        early_stopping_counter += 1\n","        if early_stopping_counter == max_early_stopping:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvNNEO0ywbB6"},"source":["# 653it [06:36,  1.65it/s]\n","# 1 EPOCH: avg loss 295121.2520458516 avg ce_l 191066.69237134888 avg ce_l2 195054.9827137034 avg KL_eps 0.0 avg KL_leps 2.1511972773435724 \n","# , roundness_f1 KL 2.4177661060603683, elongation_f2 KL 4.094873486394722, nucleus_size_f3 KL 11.658924163230026\n","#  avg KL_combined 18.097879616560263 avg KL_combined2 18.049029053512584\n","# 139it [00:30,  4.62it/s]\n","# 1 EPOCH: VAL avg loss 257265.68147720717 avg ce_l 167737.74617714944 avg ce_l2 167739.378101558 avg KL_eps 0.0 avg KL_leps 0.020880545373947994 \n","# , roundness_f1 KL 2.417999768353444, elongation_f2 KL 4.094125511050568, nucleus_size_f3 KL 12.313896843964697\n","#  avg KL_combined 16.385829108888128 avg KL_combined2 16.40207270178159\n","# saving model:  REGVAE_seed_1_main_betas300_v1_epoch_1.model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rsl6oKl8wUE2"},"source":["# -------------------------"]},{"cell_type":"markdown","metadata":{"id":"DYqxAvlXkfqL"},"source":["### ADDING A DISCRIMINATOR (an auxiliary GAN objective)"]},{"cell_type":"code","metadata":{"id":"obs814Peltbd","executionInfo":{"status":"ok","timestamp":1635261230807,"user_tz":-180,"elapsed":375,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["best_loss_discriminator = 1e+8\n","early_stopping_counter_discriminator = 1\n","max_early_stopping_discriminator = 100\n","\n","criterion = torch.nn.BCELoss()\n","real_label = 1.\n","fake_label = 0."],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"IPrbdF38mhtO","executionInfo":{"status":"ok","timestamp":1635260841017,"user_tz":-180,"elapsed":468,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# REGVAE\n","argsD = {\n","    'no_cuda': False, \n","    'seed': 1, \n","    'batch_size': 50,  # 20,\n","    'epochs': 500,\n","    'lrd': 0.001, #0.0002,\n","    #'beta1': 0.5,\n","    'outpath': PATH+'/model_output_synthetic/D',  #'./'    \n","}\n","argsD = dotdict(argsD)\n","\n","# ##args = parser.parse_args()\n","# argsD.cuda = not argsD.no_cuda and torch.cuda.is_available()\n","# device = torch.device(\"cuda\" if argsD.cuda else \"cpu\")\n","# kwargsD = {'num_workers': 0, #1,   # https://github.com/pytorch/pytorch/issues/5301\n","#           'pin_memory': False} if argsD.cuda else {}"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gnrhHvTOy-XU"},"source":["Pretrain the discriminator for a few epochs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cz8kkaIiy4Zu","executionInfo":{"status":"ok","timestamp":1635261242962,"user_tz":-180,"elapsed":402,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"c374ee85-bde2-46f6-91dc-d5a27c54464d"},"source":["## Initialize Discriminator for pre-training\n","model_name_discriminator = 'D_seed_' + str(args.seed) + ''\n","model_path_discriminator = PATH+'/model_output_synthetic/D/' + model_name_discriminator\n","print(model_name_discriminator)\n","print(model_path_discriminator)\n","\n","discriminator = Discriminator().to(device)"],"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["D_seed_1\n","drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/D/D_seed_1\n"]}]},{"cell_type":"code","metadata":{"id":"GUmmb9zly8tY","executionInfo":{"status":"ok","timestamp":1635260988910,"user_tz":-180,"elapsed":1111,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["os.mkdir(model_path_discriminator)\n","\n","import json\n","\n","with open(model_path_discriminator + '/' + model_name_discriminator + '.json', 'w') as configfile:\n","    json.dump({i:argsD[i] for i in argsD}, configfile, indent=2)"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"v52AesEoy8q0","executionInfo":{"status":"ok","timestamp":1635260992426,"user_tz":-180,"elapsed":429,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# optimizer for the disctiminator\n","optimizerD = optim.Adam(discriminator.parameters(), lr=argsD.lrd)#, betas=(argsD.beta1, 0.999))"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"2URDxDawy8ne","executionInfo":{"status":"ok","timestamp":1635260994759,"user_tz":-180,"elapsed":684,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# optimizer for the model\n","args.lr = 0.001\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"eilr1gH1zhuZ","executionInfo":{"status":"ok","timestamp":1635261249222,"user_tz":-180,"elapsed":438,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["def run_epoch_discriminator(data_loader, model, discriminator, optimizerD, train=True):\n","    #model.train()\n","    #avg_loss = 0\n","    errd = 0\n","    errd_real = 0\n","    errd_fake = 0\n","    dx = 0\n","    dg_z1 = 0\n","\n","    for batch_idx, out in tqdm(enumerate(data_loader)):\n","        #if with_x:\n","        l = out[0].to(device)  # l, fl, x, fx\n","        x = out[2].to(device)\n","        # else:\n","        #    l = out[0].to(device)  # l, fl, x, fx\n","\n","        if train: \n","          model.train()\n","          optimizer.zero_grad()\n","\n","          l_recon2, qzf_list2, _, zf_q_list2, qzeps2, _, zeps_q2,\\\n","              _, pleps2, leps_p = model.forward_xl_prior(l, x)  # x -> zf (prior -> le) -> l'\n","          sample_t = sample(l_recon2)\n","\n","          ############################\n","          # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","          ###########################\n","          ## Train with all-real batch\n","          label = torch.full((l.size(0),), real_label, dtype=torch.float, device=device)\n","          # Forward pass real batch through D\n","          output = discriminator.forward(l).view(-1)\n","          # Calculate loss on all-real batch\n","          errD_real = criterion(output, label)\n","          # Calculate gradients for D in backward pass\n","          errD_real.backward()\n","          D_x = output.mean().item()\n","\n","          ## Train with all-fake batch\n","          fake = sample_t\n","          label.fill_(fake_label)\n","          # Classify all fake batch with D\n","          output = discriminator.forward(fake.detach()).view(-1)\n","          # Calculate D's loss on the all-fake batch\n","          errD_fake = criterion(output, label)\n","          # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","          errD_fake.backward()\n","          D_G_z1 = output.mean().item()\n","          # Compute error of D as sum over the fake and the real batches\n","          errD = errD_real + errD_fake\n","          # Update D\n","          optimizerD.step()\n","\n","        else:\n","          with torch.no_grad():\n","            l_recon2, qzf_list2, _, zf_q_list2, qzeps2, _, zeps_q2,\\\n","                _, pleps2, leps_p = model.forward_xl_prior(l, x)  # x -> zf (prior -> le) -> l'\n","            sample_t = sample(l_recon2)\n","\n","            ## all-real batch\n","            label = torch.full((l.size(0),), real_label, dtype=torch.float, device=device)\n","            # Forward pass real batch through D\n","            output = discriminator.forward(l).view(-1)\n","            # Calculate loss on all-real batch\n","            errD_real = criterion(output, label)\n","            D_x = output.mean().item()\n","\n","            # process all-fake batch\n","            fake = sample_t\n","            label.fill_(fake_label)\n","            # Classify all fake batch with D\n","            output = discriminator.forward(fake.detach()).view(-1)\n","            # Calculate D's loss on the all-fake batch\n","            errD_fake = criterion(output, label)\n","            D_G_z1 = output.mean().item()\n","            # Compute error of D as sum over the fake and the real batches\n","            errD = errD_real + errD_fake\n","\n","        errd += errD.item()\n","        errd_real += errD_real.item()\n","        errd_fake += errD_fake.item()\n","        dx += D_x\n","        dg_z1 += D_G_z1\n","\n","    errd /= len(data_loader.dataset)\n","    errd_real /= len(data_loader.dataset)\n","    errd_fake /= len(data_loader.dataset)\n","    dx /= len(data_loader.dataset)\n","    dg_z1 /= len(data_loader.dataset)\n","\n","    return errd, errd_real, errd_fake, dx, dg_z1"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvMmrXEczGS2"},"source":["########### Pretrain the Discriminator\n","print('\\nStart training DISCRIMINATOR:', {i:args[i] for i in args if i!='fdvae'})\n","##G_losses = []\n","D_losses = []\n","\n","for epoch in range(1, args.epochs + 1):\n","\n","    # Train\n","    errd, errd_real, errd_fake, dx, dg_z1 = run_epoch_discriminator(train_loader, model, discriminator, optimizerD, train=True)\n","\n","    # logging train scores\n","    str_print = \"{} EPOCH: avg errd {}\".format(epoch, errd)\n","    str_print += f\" avg errd_real {errd_real}\"\n","    str_print += f\" avg errd_fake {errd_fake}\"\n","    str_print += f\" avg dx {dx}\"\n","    str_print += f\" avg dg_z1 {dg_z1}\"\n","    print(str_print)\n","\n","    # Val\n","    val_errd, val_errd_real, val_errd_fake, val_dx, val_dg_z1 = run_epoch_discriminator(val_loader, model, discriminator, optimizerD, train=False)\n","\n","    # logging train scores\n","    str_print = \"{} EPOCH: VAL avg errd {}\".format(epoch, val_errd)\n","    str_print += f\" avg errd_real {val_errd_real}\"\n","    str_print += f\" avg errd_fake {val_errd_fake}\"\n","    str_print += f\" avg dx {val_dx}\"\n","    str_print += f\" avg dg_z1 {val_dg_z1}\"\n","    print(str_print)\n","\n","    D_losses.append(val_errd)\n","\n","    if val_errd < best_loss_discriminator:\n","        early_stopping_counter_discriminator = 1\n","\n","        best_loss_discriminator = val_errd\n","\n","        print(\"saving model: \", model_name_discriminator + f'_epoch_{epoch}' + '.model')\n","        torch.save(discriminator, model_path_discriminator + '/' + model_name_discriminator + f'_epoch_{epoch}' + '.model')\n","    else:\n","        #######\n","        if epoch >= 1 and epoch % 10 == 0:\n","            print(\"RESERVE saving model: \", model_name_discriminator + f'_epoch_{epoch}' + '.model')\n","            torch.save(discriminator, model_path_discriminator + '/' + model_name_discriminator + f'_epoch_{epoch}' + '.model')\n","        #######   \n","        early_stopping_counter_discriminator += 1\n","        if early_stopping_counter_discriminator == max_early_stopping_discriminator:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hr406FpDJtHZ"},"source":["# 653it [02:21,  4.61it/s]\n","# 1 EPOCH: avg errd 0.025731841070329678 avg errd_real 0.015352839881301742 avg errd_fake 0.01037900117715341 avg dx 0.009599916219280167 avg dg_z1 0.008043021754695004\n","# 139it [00:17,  8.10it/s]\n","# 1 EPOCH: VAL avg errd 0.026170091104865144 avg errd_real 0.015713524436648016 avg errd_fake 0.010456566741304183 avg dx 0.00946238425447978 avg dg_z1 0.008092846156060868\n","# saving model:  D_seed_1_epoch_1.model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6-a3WcezGQR"},"source":["Load the pretrained discriminator and train the combined objectve"]},{"cell_type":"code","metadata":{"id":"tEdzeEdkKtJO","executionInfo":{"status":"ok","timestamp":1635261497674,"user_tz":-180,"elapsed":460,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["best_loss_discriminator = 1e+8\n","early_stopping_counter_discriminator = 1\n","max_early_stopping_discriminator = 100\n","\n","criterion = torch.nn.BCELoss()\n","real_label = 1.\n","fake_label = 0."],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fom8OBX28-Mp","executionInfo":{"status":"ok","timestamp":1635261523455,"user_tz":-180,"elapsed":388,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}},"outputId":"e25151e2-826b-4bd9-b954-0fa80f8ded0a"},"source":["model_name_discriminator = 'D_seed_' + str(args.seed) + ''\n","model_path_discriminator = PATH+'/model_output_synthetic/D/' + model_name_discriminator\n","print(model_name_discriminator)\n","print(model_path_discriminator)\n","\n","discriminator = torch.load(model_path_discriminator + '/' + model_name_discriminator + '_epoch_1' + '.model')#, map_location=torch.device('cpu'))"],"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["D_seed_1\n","drive/My Drive/Colab Notebooks/GEN/model_output_synthetic/D/D_seed_1\n"]}]},{"cell_type":"code","metadata":{"id":"LgLdmU_RzGNV"},"source":["# base_model_name_discriminator = 'D_seed_' + str(args.seed) + ''\n","# base_model_path_discriminator = PATH+'/FDVA_output/D/' + base_model_name_discriminator\n","# print(base_model_name_discriminator)\n","# print(base_model_path_discriminator)\n","\n","# discriminator = torch.load(base_model_path_discriminator + '/' + base_model_name_discriminator + '_epoch_125' + '.model')#, map_location=torch.device('cpu'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayglsCT7zgIq","executionInfo":{"status":"ok","timestamp":1635261527005,"user_tz":-180,"elapsed":442,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# optimizer for the disctiminator\n","optimizerD = optim.Adam(discriminator.parameters(), lr=argsD.lrd)#, betas=(argsD.beta1, 0.999))"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2LrFyAAzgHT","executionInfo":{"status":"ok","timestamp":1635261527646,"user_tz":-180,"elapsed":2,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["# optimizer for the model\n","args.lr = 0.001\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDyW3FJQrBuA","executionInfo":{"status":"ok","timestamp":1635261528166,"user_tz":-180,"elapsed":2,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["XI_GEN = 1000000"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"sv2mzBGH-Av3","executionInfo":{"status":"ok","timestamp":1635262170050,"user_tz":-180,"elapsed":576,"user":{"displayName":"Stepan Veretennikov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13277347111185896501"}}},"source":["def run_epoch_l_gan(data_loader, model, discriminator, optimizer, optimizerD, epoch, rec_freq=None, path_reconstructions='', train=True):\n","    #model.train()\n","    #discriminator.train()\n","    avg_loss = 0\n","    ce_l = 0\n","    ce_l2 = 0\n","    kl_zeps = 0\n","    kl_leps = 0\n","    kls_zfk = [0] * model.fdvae.num_features\n","    kl_combined = 0\n","    kl_combined2 = 0\n","\n","    errd = 0\n","    errd_real = 0\n","    errd_fake = 0\n","    dx = 0\n","    dg_z1 = 0\n","    dg_z2 = 0\n","    errg = 0\n","\n","    for batch_idx, out in tqdm(enumerate(data_loader)):\n","        #if with_x:\n","        l = out[0].to(device)  # l, fl, x, fx\n","        x = out[2].to(device)\n","        # else:\n","        #    l = out[0].to(device)  # l, fl, x, fx\n","\n","        if train and rec_freq and (epoch % rec_freq == 0) and (batch_idx == 1):\n","            save_reconstructions_l(model, l, path_reconstructions)\n","            #save_reconstructions_xl(model, l, x, path_reconstructions)\n","            save_reconstructions_xl_prior(model, l, x, path_reconstructions)\n","            save_reconstructions_xl_prior_same(model, l, x, path_reconstructions)\n","\n","        if train: \n","          model.train()\n","          discriminator.train()\n","          optimizer.zero_grad()\n","          optimizerD.zero_grad()\n","\n","          #if with_x:\n","          loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l, x)  # MI, MI2, TC, LOGQZ, LOGQZ_prodmarginals\n","          # else:\n","          #   loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, _ = model.loss_function_l(l)  # this is only for case when we don't want to use the regularizer\n","\n","          sample_t = sample(l_recon2)\n","\n","          ##### (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","          ## Train with all-real batch\n","          label = torch.full((l.size(0),), real_label, dtype=torch.float, device=device)\n","          # Forward pass real batch through D\n","          output = discriminator.forward(l).view(-1)\n","          # Calculate loss on all-real batch\n","          errD_real = criterion(output, label)\n","          # Calculate gradients for D in backward pass\n","          errD_real.backward()\n","          D_x = output.mean().item()\n","\n","          ## Train with all-fake batch\n","          fake = sample_t\n","          label.fill_(fake_label)\n","          # Classify all fake batch with D\n","          output = discriminator.forward(fake.detach()).view(-1)\n","          # Calculate D's loss on the all-fake batch\n","          errD_fake = criterion(output, label)\n","          # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","          errD_fake.backward()\n","          D_G_z1 = output.mean().item()\n","          # Compute error of D as sum over the fake and the real batches\n","          errD = errD_real + errD_fake\n","          # Update D every 10 batches\n","          #if epoch % 2 == 1 and batch_idx == 0:\n","          if batch_idx % 10 == 0:\n","            optimizerD.step()\n","\n","          ##### (2) Update G network: maximize log(D(G(z)))\n","          label.fill_(real_label)  # fake labels are real for generator cost\n","          # Since we just updated D, perform another forward pass of all-fake batch through D\n","          output = discriminator.forward(fake).view(-1)\n","          # Calculate G's loss based on this output\n","          errG = criterion(output, label)\n","          # Calculate gradients for G\n","          loss += XI_GEN * errG\n","          D_G_z2 = output.mean().item()\n","          # Update G\n","          loss.backward()\n","          optimizer.step()\n","\n","        else:\n","          with torch.no_grad():\n","            #if with_x:\n","            loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, l_recon2 = model.loss_function_l(l, x)  # MI, MI2, TC, LOGQZ, LOGQZ_prodmarginals\n","            # else:\n","            #   loss, CE_l, KL_zeps, KL_leps, KLs_zfk, CE_l2, KL_combined, KL_combined2, l_recon, _ = model.loss_function_l(l)  # this is only for case when we don't want to use the regularizer\n","            sample_t = sample(l_recon2)\n","\n","            ##### D network\n","            ## Process all-real batch\n","            label = torch.full((l.size(0),), real_label, dtype=torch.float, device=device)\n","            # Forward pass real batch through D\n","            output = discriminator.forward(l).view(-1)\n","            # Calculate loss on all-real batch\n","            errD_real = criterion(output, label)\n","            D_x = output.mean().item()\n","\n","            ## Process all-fake batch\n","            fake = sample_t\n","            label.fill_(fake_label)\n","            # Classify all fake batch with D\n","            output = discriminator.forward(fake.detach()).view(-1)\n","            # Calculate D's loss on the all-fake batch\n","            errD_fake = criterion(output, label)\n","            D_G_z1 = output.mean().item()\n","            # Compute error of D as sum over the fake and the real batches\n","            errD = errD_real + errD_fake\n","\n","            ##### G network\n","            label.fill_(real_label)  # fake labels are real for generator cost\n","            # Since we just updated D, perform another forward pass of all-fake batch through D\n","            output = discriminator.forward(fake).view(-1)\n","            # Calculate G's loss based on this output\n","            errG = criterion(output, label)\n","            # Calculate gradients for G\n","            loss += XI_GEN * errG\n","            D_G_z2 = output.mean().item()\n","\n","        errd += errD.item()\n","        errd_real += errD_real.item()\n","        errd_fake += errD_fake.item()\n","        dx += D_x\n","        dg_z1 += D_G_z1\n","        dg_z2 += D_G_z2\n","        errg += errG.item()\n","\n","        avg_loss += loss.item()\n","        ce_l += CE_l.item()\n","        ce_l2 += CE_l2.item()\n","        kl_zeps += KL_zeps#.item()\n","        kl_leps += KL_leps.item()\n","        for k in range(model.fdvae.num_features):\n","            kls_zfk[k] += KLs_zfk[k].item()\n","        kl_combined += KL_combined.item()\n","        kl_combined2 += KL_combined2.item()\n","\n","    avg_loss /= len(data_loader.dataset)\n","    ce_l /= len(data_loader.dataset)\n","    ce_l2 /= len(data_loader.dataset)\n","    kl_zeps /= len(data_loader.dataset)\n","    kl_leps /= len(data_loader.dataset)\n","    for k in range(model.fdvae.num_features):\n","        kls_zfk[k] /= len(data_loader.dataset)\n","    kl_combined /= len(data_loader.dataset)\n","    kl_combined2 /= len(data_loader.dataset)\n","    errd /= len(data_loader.dataset)\n","    errd_real /= len(data_loader.dataset)\n","    errd_fake /= len(data_loader.dataset)\n","    dx /= len(data_loader.dataset)\n","    dg_z1 /= len(data_loader.dataset)\n","    dg_z2 /= len(data_loader.dataset)\n","    errg /= len(data_loader.dataset)\n","\n","    return avg_loss, ce_l, ce_l2, kl_zeps, kl_leps, kls_zfk, kl_combined, kl_combined2, errd, errd_real, errd_fake, dx, dg_z1, dg_z2, errg"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yx51ESaCOKF4"},"source":["######## Training loop REGVAE (STEP 3) + GAN objective\n","print('\\nStart training [[[STEP 3 GAN]]]:', {i:args[i] for i in args if i!='fdvae'})\n","G_losses = []\n","D_losses = []\n","\n","for epoch in range(1, args.epochs + 1):\n","\n","    # Train\n","    train_loss, ce_l, ce_l2, kl_zeps, kl_leps, kls_zfk, kl_combined, kl_combined2,\\\n","                             errd, errd_real, errd_fake, dx, dg_z1, dg_z2, errg = run_epoch_l_gan(train_loader, model, discriminator, optimizer, optimizerD, \n","                                                                                                  epoch, rec_freq=1, path_reconstructions=model_path + '/', train=True)\n","\n","    # logging train scores\n","    str_print = \"{} EPOCH: avg loss {}\".format(epoch, train_loss)\n","    str_print += f\" avg ce_l {ce_l}\"\n","    str_print += f\" avg ce_l2 {ce_l2}\"\n","    str_print += f\" avg KL_eps {kl_zeps}\"\n","    str_print += f\" avg KL_leps {kl_leps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {kls_zfk[k]}\"\n","    str_print += f\"\\n avg KL_combined {kl_combined}\"\n","    str_print += f\" avg KL_combined2 {kl_combined2}\"\n","    str_print += f\"\\n avg errd {errd}\"\n","    str_print += f\" avg errd_real {errd_real}\"\n","    str_print += f\" avg errd_fake {errd_fake}\"\n","    str_print += f\" avg dx {dx}\"\n","    str_print += f\" avg dg_z1 {dg_z1}\"\n","    str_print += f\" avg dg_z2 {dg_z2}\"\n","    str_print += f\" avg errg {errg}\"\n","    print(str_print)\n","\n","    # Val\n","    val_loss, val_ce_l, val_ce_l2, val_kl_zeps, val_kl_leps, val_kls_zfk, val_kl_combined, val_kl_combined2,\\\n","                          val_errd, val_errd_real, val_errd_fake, val_dx, val_dg_z1, val_dg_z2, val_errg = run_epoch_l_gan(val_loader, model, discriminator, optimizer, optimizerD, \n","                                                                                                                           epoch, rec_freq=1, path_reconstructions=model_path + '/', train=False)\n","\n","    # logging val scores\n","    str_print = \"{} EPOCH: VAL avg loss {}\".format(epoch, val_loss)\n","    str_print += f\" avg ce_l {val_ce_l}\"\n","    str_print += f\" avg ce_l2 {val_ce_l2}\"\n","    str_print += f\" avg KL_eps {val_kl_zeps}\"\n","    str_print += f\" avg KL_leps {val_kl_leps} \\n\"\n","    for k in range(model.fdvae.num_features):      \n","        str_print += f\", {train_data.features_names_x[k]} KL {val_kls_zfk[k]}\"\n","    str_print += f\"\\n avg KL_combined {val_kl_combined}\"\n","    str_print += f\" avg KL_combined2 {val_kl_combined2}\"\n","    str_print += f\"\\n avg errd {val_errd}\"\n","    str_print += f\" avg errd_real {val_errd_real}\"\n","    str_print += f\" avg errd_fake {val_errd_fake}\"\n","    str_print += f\" avg dx {val_dx}\"\n","    str_print += f\" avg dg_z1 {val_dg_z1}\"\n","    str_print += f\" avg dg_z2 {val_dg_z2}\"\n","    str_print += f\" avg errg {val_errg}\"\n","    print(str_print)\n","\n","    G_losses.append(val_errg)\n","    D_losses.append(val_errd)\n","\n","    #######\n","    # if epoch > 1:\n","    #     print(\"RRRRRRRRESERVE saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","    #     torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","    #     torch.save(discriminator, model_path_discriminator + '/' + model_name_discriminator + f'_epoch_{epoch}' + '.model')\n","    #######\n","\n","    if val_loss < best_loss:\n","        early_stopping_counter = 1\n","\n","        best_loss =  val_loss\n","\n","        print(\"saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","        torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","    else:\n","        #######\n","        if epoch >= 1 and epoch % 10 == 0:\n","            print(\"RESERVE saving model: \", model_name + f'_epoch_{epoch}' + '.model')\n","            torch.save(model, model_path + '/' + model_name + f'_epoch_{epoch}' + '.model')\n","        #######   \n","        early_stopping_counter += 1\n","        if early_stopping_counter == max_early_stopping:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycixIwBaLwde"},"source":["# 653it [08:05,  1.35it/s]\n","# 1 EPOCH: avg loss 289151.01078861067 avg ce_l 157206.03886351796 avg ce_l2 180442.97235418519 avg KL_eps 0.0 avg KL_leps 0.5841221608799044 \n","# , roundness_f1 KL 2.412954923863773, elongation_f2 KL 4.092082730713976, nucleus_size_f3 KL 11.67125448121176\n","#  avg KL_combined 16.529692080770133 avg KL_combined2 16.545611257801845\n","#  avg errd 0.015494498402052902 avg errd_real 0.008945446051539597 avg errd_fake 0.006549052354794986 avg dx 0.013661521159218183 avg dg_z1 0.00500406309477929 avg dg_z2 0.004678837584775385 avg errg 0.035978537051842195\n","# 139it [00:37,  3.68it/s]\n","# 1 EPOCH: VAL avg loss 291592.6690709752 avg ce_l 157421.42188401616 avg ce_l2 180489.10538084246 avg KL_eps 0.0 avg KL_leps 0.4629769557759174 \n","# , roundness_f1 KL 2.4202314355919556, elongation_f2 KL 4.107097751201403, nucleus_size_f3 KL 12.220713593955681\n","#  avg KL_combined 16.77856865303405 avg KL_combined2 16.74273874466638\n","#  avg errd 0.009150887805639631 avg errd_real 0.0036932395795866444 avg errd_fake 0.005457648245399561 avg dx 0.016831455198726555 avg dg_z1 0.004269581364410775 avg dg_z2 0.004269581364410775 avg errg 0.038070793964927484"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MccGvwlBX554"},"source":["####torch.save(discriminator, model_path_discriminator + '/' + model_name_discriminator + f'_epoch_{133}' + '.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzbSB2VNX_1A"},"source":["###torch.save(model, model_path + '/' + model_name + f'_epoch_{133}' + '.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5zjBsVryQnW"},"source":[""],"execution_count":null,"outputs":[]}]}